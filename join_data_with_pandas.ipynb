{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wDRSFrZa7Y-I2RBcqtZY6258OPkEPhtA",
      "authorship_tag": "ABX9TyOM4zB67TEcRTfx0bF+PmHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavo-plc/joinWithPandas/blob/main/join_data_with_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INNER JOIN"
      ],
      "metadata": {
        "id": "uDJd1lcvYFcj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-Lggkvhmch6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d1ea66-4898-4d96-c7a5-f0acab569609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['rid', 'vid', 'owner_x', 'address', 'zip', 'make', 'model', 'year',\n",
            "       'fuel_type', 'owner_y'],\n",
            "      dtype='object')\n",
            "Index(['rid', 'vid', 'owner_own', 'address', 'zip', 'make', 'model', 'year',\n",
            "       'fuel_type', 'owner_veh'],\n",
            "      dtype='object')\n",
            "fuel_type\n",
            "HYBRID                    2792\n",
            "GASOLINE                   611\n",
            "FLEX FUEL                   89\n",
            "COMPRESSED NATURAL GAS      27\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# READING FILES\n",
        "\n",
        "path1 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/''taxi_owners.p'\n",
        "\n",
        "taxi_owners = pd.read_pickle(path1)\n",
        "\n",
        "path2 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/taxi_vehicles.p'\n",
        "\n",
        "taxi_veh = pd.read_pickle(path2)\n",
        "\n",
        "\n",
        "# INNER JOIN\n",
        "\n",
        "\n",
        "# Merge the taxi_owners and taxi_veh tables\n",
        "taxi_own_veh = taxi_owners.merge(taxi_veh, on = 'vid')\n",
        "\n",
        "# Print the column names of the taxi_own_veh\n",
        "print(taxi_own_veh.columns)\n",
        "\n",
        "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
        "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes = ('_own', '_veh'))\n",
        "\n",
        "# Print the column names of taxi_own_veh\n",
        "print(taxi_own_veh.columns)\n",
        "\n",
        "# Print the value_counts to find the most popular fuel_type\n",
        "print(taxi_own_veh['fuel_type'].value_counts())\n",
        "\n",
        "\n",
        "# Inner joins and number of rows returned\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHBussSD6usx",
        "outputId": "2a542bc3-c532-44f0-a3c9-8f385abc5311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# READING FILES\n",
        "\n",
        "path3 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/ward.p'\n",
        "\n",
        "wards = pd.read_pickle(path3)\n",
        "\n",
        "path4 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/census.p'\n",
        "\n",
        "census = pd.read_pickle(path4)\n",
        "\n",
        "\n",
        "# Inner joins and number of rows returned: inner joins only return the rows with matching values in both tables.\n",
        "\n",
        "\n",
        "print(wards.head())\n",
        "print(census.head())\n",
        "\n",
        "# Merge the wards and census tables on the ward column\n",
        "wards_census = wards.merge(census, on = 'ward')\n",
        "\n",
        "# Print the shape of wards_census\n",
        "print('wards_census table shape:', wards_census.shape)\n",
        "print()\n",
        "#altering wards table\n",
        "wards_altered = wards\n",
        "wards_altered.loc[0, ['ward']] = 61\n",
        "\n",
        "# Print the first few rows of the wards_altered table to view the change\n",
        "print(wards_altered[['ward']].head())\n",
        "print()\n",
        "# Merge the wards_altered and census tables on the ward column\n",
        "wards_altered_census = wards_altered.merge(census, on = 'ward')\n",
        "\n",
        "# Print the shape of wards_altered_census\n",
        "print('wards_altered_census table shape:', wards_altered_census.shape)\n",
        "print()\n",
        "\n",
        "# it only printed 49 rows instead of 50 because there was no 50 matching values on both tables, since we altered the ward value to 61\n",
        "\n",
        "#altering census table\n",
        "\n",
        "census_altered = census\n",
        "census_altered.loc[0, ['ward']] = 'none'\n",
        "\n",
        "# Print the first few rows of the census_altered table to view the change\n",
        "print(census_altered[['ward']].head())\n",
        "\n",
        "# Merge the wards and census_altered tables on the ward column\n",
        "wards_census_altered = wards.merge(census_altered, on = 'ward')\n",
        "\n",
        "# Print the shape of wards_census_altered\n",
        "print('wards_census_altered table shape:', wards_census_altered.shape)\n",
        "\n",
        "# it only printed 49 rows instead of 50 because there was no 50 matching values on both tables, since we altered the ward value to 61\n",
        "\n",
        "# Attention: .merge() only returns rows where the values match in both tables.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHlarKapikip",
        "outputId": "6620ab7d-39db-4fb4-fee8-a4f26bbe5710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ward            alderman                          address    zip\n",
            "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
            "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
            "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
            "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
            "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n",
            "  ward  pop_2000  pop_2010 change                                  address  \\\n",
            "0    1     52951     56149     6%              2765 WEST SAINT MARY STREET   \n",
            "1    2     54361     55805     3%                 WM WASTE MANAGEMENT 1500   \n",
            "2    3     40385     53039    31%                      17 EAST 38TH STREET   \n",
            "3    4     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL   \n",
            "4    5     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE   \n",
            "\n",
            "     zip  \n",
            "0  60647  \n",
            "1  60622  \n",
            "2  60653  \n",
            "3  60653  \n",
            "4  60637  \n",
            "wards_census table shape: (50, 9)\n",
            "\n",
            "  ward\n",
            "0   61\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "\n",
            "wards_altered_census table shape: (49, 9)\n",
            "\n",
            "   ward\n",
            "0  none\n",
            "1     2\n",
            "2     3\n",
            "3     4\n",
            "4     5\n",
            "wards_census_altered table shape: (49, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-to-many relationships: when one row of Table A can relate to more than one rows of Table B.\n",
        "# Example: ward 1 can have more than one businesses related to it. It's a one to many relation.\n",
        "\n",
        "\n",
        "# ONE TO MANY MERGE\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# READING FILES\n",
        "\n",
        "\n",
        "path5 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/licenses.p'\n",
        "\n",
        "licenses = pd.read_pickle(path5)\n",
        "\n",
        "path6 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/business_owners.p'\n",
        "\n",
        "biz_owners = pd.read_pickle(path6)\n",
        "\n",
        "print(licenses.head())\n",
        "print()\n",
        "print(biz_owners.head())\n",
        "print()\n",
        "\n",
        "# Merge the licenses and biz_owners table on account\n",
        "licenses_owners = licenses.merge(biz_owners, on = 'account')\n",
        "print(licenses_owners.head())\n",
        "print()\n",
        "\n",
        "# Group the results by title then count the number of accounts\n",
        "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
        "# this line COUNTS the number of diff ACCOUNTS grouped by TITLE\n",
        "# THE CAPITAL WORDS SHOWS THE FUNCTION'S ARGUMENTS\n",
        "\n",
        "# Sort the counted_df in descending order\n",
        "sorted_df = counted_df.sort_values('account', ascending = False)\n",
        "\n",
        "# Use .head() method to print the first few rows of sorted_df\n",
        "print(sorted_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdR_ttRXsD6b",
        "outputId": "233bb239-acfc-4cda-ab2d-662a0066794a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  account ward  aid                   business               address    zip\n",
            "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
            "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
            "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
            "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
            "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n",
            "\n",
            "  account first_name  last_name      title\n",
            "0      10      PEARL    SHERMAN  PRESIDENT\n",
            "1      10      PEARL    SHERMAN  SECRETARY\n",
            "2   10002     WALTER     MROZEK    PARTNER\n",
            "3   10002     CELINA     BYRDAK    PARTNER\n",
            "4   10005      IRENE  ROSENFELD  PRESIDENT\n",
            "\n",
            "  account ward  aid              business              address    zip  \\\n",
            "0  307071    3  743  REGGIE'S BAR & GRILL      2105 S STATE ST  60616   \n",
            "1      10   10  829            HONEYBEERS  13200 S HOUSTON AVE  60633   \n",
            "2      10   10  829            HONEYBEERS  13200 S HOUSTON AVE  60633   \n",
            "3   10002   14  775           CELINA DELI    5089 S ARCHER AVE  60632   \n",
            "4   10002   14  775           CELINA DELI    5089 S ARCHER AVE  60632   \n",
            "\n",
            "  first_name last_name      title  \n",
            "0     ROBERT     GLICK     MEMBER  \n",
            "1      PEARL   SHERMAN  PRESIDENT  \n",
            "2      PEARL   SHERMAN  SECRETARY  \n",
            "3     WALTER    MROZEK    PARTNER  \n",
            "4     CELINA    BYRDAK    PARTNER  \n",
            "\n",
            "                 account\n",
            "title                   \n",
            "PRESIDENT           6259\n",
            "SECRETARY           5205\n",
            "SOLE PROPRIETOR     1658\n",
            "OTHER               1200\n",
            "VICE PRESIDENT       970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging multiple DataFrames\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# READING FILES\n",
        "\n",
        "\n",
        "path7 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/cta_calendar.p'\n",
        "\n",
        "cal = pd.read_pickle(path7)\n",
        "\n",
        "path8 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/cta_ridership.p'\n",
        "\n",
        "ridership = pd.read_pickle(path8)\n",
        "\n",
        "path9 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/stations.p'\n",
        "\n",
        "stations = pd.read_pickle(path9)\n",
        "\n",
        "print(cal.head())\n",
        "print()\n",
        "print(ridership.head())\n",
        "print()\n",
        "print(stations.head())\n",
        "print()\n",
        "\n",
        "\n",
        "# QUESTION: find the total number of rides provided to passengers passing through the Wilson station (station_name == 'Wilson') when riding Chicago's public transportation system on weekdays (day_type == 'Weekday') in July (month == 7)\n",
        "\n",
        "# TO MERGE THREE TABLES:\n",
        "# df1.merge(df2, on='col') \\\n",
        "#     .merge(df3, on='col')\n",
        "\n",
        "\n",
        "# merging cal and ridership to have just one table with all this content, since\n",
        "# almost all columns from cal are already in ridership\n",
        "\n",
        "# Merge the ridership and cal tables MERGING TWO TABLES!\n",
        "ridership_cal = ridership.merge(cal, on = ['year', 'month', 'day'])\n",
        "print(ridership_cal)\n",
        "print()\n",
        "\n",
        "# MERGING THREE TABLES AT ONCE!:\n",
        "\n",
        "ridership_cal_stations = ridership.merge(cal, on = ['year', 'month', 'day']) \\\n",
        "                                  .merge(stations, on = 'station_id')\n",
        "\n",
        "print(ridership_cal_stations)\n",
        "print()\n",
        "\n",
        "# SINCE THE TABLES WERE MERGED WE CAN NOW CREATE A FILTER TO FACILITATE SELECTING DATA FROM THE MERGED TABLE\n",
        "\n",
        "# Create a filter to filter ridership_cal_stations\n",
        "filter_criteria = ((ridership_cal_stations['station_name'] == 'Wilson') & (ridership_cal_stations['day_type'] == 'Weekday') & (ridership_cal_stations['month'] == 7))\n",
        "\n",
        "#printing the sum of these rides on July weekdays on Wilson's station\n",
        "# synthax: df.loc[lines, columns]\n",
        "\n",
        "print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK18ytIiQtMP",
        "outputId": "b9ffdbb4-d28a-4cd6-a3cd-2928d5d0594b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  month  day        day_type\n",
            "0  2019      1    1  Sunday/Holiday\n",
            "1  2019      1    2         Weekday\n",
            "2  2019      1    3         Weekday\n",
            "3  2019      1    4         Weekday\n",
            "4  2019      1    5        Saturday\n",
            "\n",
            "  station_id  year  month  day  rides\n",
            "0      40010  2019      1    1    576\n",
            "1      40010  2019      1    2   1457\n",
            "2      40010  2019      1    3   1543\n",
            "3      40010  2019      1    4   1621\n",
            "4      40010  2019      1    5    719\n",
            "\n",
            "  station_id        station_name                 location\n",
            "0      40010  Austin-Forest Park  (41.870851, -87.776812)\n",
            "1      40020         Harlem-Lake  (41.886848, -87.803176)\n",
            "2      40030        Pulaski-Lake  (41.885412, -87.725404)\n",
            "3      40040        Quincy/Wells   (41.878723, -87.63374)\n",
            "4      40050               Davis   (42.04771, -87.683543)\n",
            "\n",
            "     station_id  year  month  day  rides        day_type\n",
            "0         40010  2019      1    1    576  Sunday/Holiday\n",
            "1         40010  2019      1    2   1457         Weekday\n",
            "2         40010  2019      1    3   1543         Weekday\n",
            "3         40010  2019      1    4   1621         Weekday\n",
            "4         40010  2019      1    5    719        Saturday\n",
            "...         ...   ...    ...  ...    ...             ...\n",
            "3280      41660  2019     12   27  13898         Weekday\n",
            "3281      41660  2019     12   28   9485        Saturday\n",
            "3282      41660  2019     12   29   7581  Sunday/Holiday\n",
            "3283      41660  2019     12   30  15332         Weekday\n",
            "3284      41660  2019     12   31  13430         Weekday\n",
            "\n",
            "[3285 rows x 6 columns]\n",
            "\n",
            "     station_id  year  month  day  rides        day_type        station_name  \\\n",
            "0         40010  2019      1    1    576  Sunday/Holiday  Austin-Forest Park   \n",
            "1         40010  2019      1    2   1457         Weekday  Austin-Forest Park   \n",
            "2         40010  2019      1    3   1543         Weekday  Austin-Forest Park   \n",
            "3         40010  2019      1    4   1621         Weekday  Austin-Forest Park   \n",
            "4         40010  2019      1    5    719        Saturday  Austin-Forest Park   \n",
            "...         ...   ...    ...  ...    ...             ...                 ...   \n",
            "3280      41660  2019     12   27  13898         Weekday          Lake/State   \n",
            "3281      41660  2019     12   28   9485        Saturday          Lake/State   \n",
            "3282      41660  2019     12   29   7581  Sunday/Holiday          Lake/State   \n",
            "3283      41660  2019     12   30  15332         Weekday          Lake/State   \n",
            "3284      41660  2019     12   31  13430         Weekday          Lake/State   \n",
            "\n",
            "                     location  \n",
            "0     (41.870851, -87.776812)  \n",
            "1     (41.870851, -87.776812)  \n",
            "2     (41.870851, -87.776812)  \n",
            "3     (41.870851, -87.776812)  \n",
            "4     (41.870851, -87.776812)  \n",
            "...                       ...  \n",
            "3280  (41.884809, -87.627813)  \n",
            "3281  (41.884809, -87.627813)  \n",
            "3282  (41.884809, -87.627813)  \n",
            "3283  (41.884809, -87.627813)  \n",
            "3284  (41.884809, -87.627813)  \n",
            "\n",
            "[3285 rows x 8 columns]\n",
            "\n",
            "140005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging multiple DataFrames\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# READING FILES\n",
        "\n",
        "\n",
        "path10 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/licenses.p'\n",
        "\n",
        "licenses = pd.read_pickle(path10)\n",
        "\n",
        "path11 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/ward.p'\n",
        "\n",
        "wards = pd.read_pickle(path11)\n",
        "\n",
        "path12 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/zip_demo.p'\n",
        "\n",
        "zip_demo = pd.read_pickle(path12)\n",
        "\n",
        "print(licenses.head())\n",
        "print()\n",
        "print(wards.head())\n",
        "print()\n",
        "print(zip_demo.head())\n",
        "print()\n",
        "\n",
        "\n",
        "# Merge licenses and zip_demo, on zip; and merge the wards on ward\n",
        "licenses_zip_ward = licenses.merge(zip_demo, on = 'zip') \\\n",
        "            \t\t\t.merge(wards, on = 'ward')\n",
        "\n",
        "# PRINTING THE RESULTS WITHOUT A FILTER_CRITERIA, JUST USING THE GROUPBY AND AGG METHODS\n",
        "\n",
        "# Print the results by alderman and show median income\n",
        "print(licenses_zip_ward.groupby('alderman').agg({'income':'median'}))\n",
        "\n",
        "# RESULT SHOWING THE INCOME MEDIAN FOR EACH ALDERMAN: CMD ABOVE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX3Czutscx0S",
        "outputId": "1ac78028-7fc5-472a-8ca1-c7c485aa6b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  account ward  aid                   business               address    zip\n",
            "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
            "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
            "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
            "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
            "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n",
            "\n",
            "  ward            alderman                          address    zip\n",
            "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
            "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
            "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
            "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
            "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n",
            "\n",
            "     zip  income\n",
            "0  60630   70122\n",
            "1  60640   50488\n",
            "2  60622   87143\n",
            "3  60614  100116\n",
            "4  60608   41226\n",
            "\n",
            "                             income\n",
            "alderman                           \n",
            "Ameya Pawar                 66246.0\n",
            "Anthony A. Beale            38206.0\n",
            "Anthony V. Napolitano       82226.0\n",
            "Ariel E. Reyboras           41307.0\n",
            "Brendan Reilly             110215.0\n",
            "Brian Hopkins               87143.0\n",
            "Carlos Ramirez-Rosa         66246.0\n",
            "Carrie M. Austin            38206.0\n",
            "Chris Taliaferro            55566.0\n",
            "Daniel \"Danny\" Solis        41226.0\n",
            "David H. Moore              33304.0\n",
            "Deborah Mell                66246.0\n",
            "Debra L. Silverstein        50554.0\n",
            "Derrick G. Curtis           65770.0\n",
            "Edward M. Burke             42335.0\n",
            "Emma M. Mitts               36283.0\n",
            "George Cardenas             33959.0\n",
            "Gilbert Villegas            41307.0\n",
            "Gregory I. Mitchell         24941.0\n",
            "Harry Osterman              45442.0\n",
            "Howard B. Brookins, Jr.     33304.0\n",
            "James Cappleman             79565.0\n",
            "Jason C. Ervin              41226.0\n",
            "Joe Moore                   39163.0\n",
            "John S. Arena               70122.0\n",
            "Leslie A. Hairston          28024.0\n",
            "Margaret Laurino            70122.0\n",
            "Marty Quinn                 67045.0\n",
            "Matthew J. O'Shea           59488.0\n",
            "Michael R. Zalewski         42335.0\n",
            "Michael Scott, Jr.          31445.0\n",
            "Michelle A. Harris          32558.0\n",
            "Michelle Smith             100116.0\n",
            "Milagros \"Milly\" Santiago   41307.0\n",
            "Nicholas Sposato            62223.0\n",
            "Pat Dowell                  46340.0\n",
            "Patrick Daley Thompson      41226.0\n",
            "Patrick J. O'Connor         50554.0\n",
            "Proco \"Joe\" Moreno          87143.0\n",
            "Raymond A. Lopez            33959.0\n",
            "Ricardo Munoz               31445.0\n",
            "Roberto Maldonado           68223.0\n",
            "Roderick T. Sawyer          32558.0\n",
            "Scott Waguespack            68223.0\n",
            "Susan Sadlowski Garza       38417.0\n",
            "Tom Tunney                  88708.0\n",
            "Toni L. Foulkes             27573.0\n",
            "Walter Burnett, Jr.         87143.0\n",
            "William D. Burns           107811.0\n",
            "Willie B. Cochran           28024.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-to-many merge with multiple tables\n",
        "\n",
        "\n",
        "# PROBLEM: However, you have to choose a location in the city to put your goat farm. You need a location with a great deal of space and relatively few businesses and people around to avoid complaints about the smell.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# READING FILES\n",
        "\n",
        "\n",
        "path13 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/land_use.p'\n",
        "\n",
        "land_use = pd.read_pickle(path13)\n",
        "\n",
        "path14 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/census.p'\n",
        "\n",
        "census = pd.read_pickle(path14)\n",
        "\n",
        "path15 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/licenses.p'\n",
        "\n",
        "licenses = pd.read_pickle(path15)\n",
        "\n",
        "\n",
        "print(land_use.head())\n",
        "print()\n",
        "print(census.head())\n",
        "print()\n",
        "print(licenses.head())\n",
        "print()\n",
        "\n",
        "# Merge land_use and census and merge result with licenses including suffixes\n",
        "land_cen_lic = land_use.merge(census, on = 'ward') \\\n",
        "                        .merge(licenses, on = 'ward', suffixes = ('_cen', '_lic'))\n",
        "\n",
        "print(land_cen_lic.columns)\n",
        "print()\n",
        "\n",
        "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
        "# AFTER THIS, THE FEATURE ACCOUNT WILL HAVE THE TOTAL NUMBER OF ACCOUNTS FOR EACH WARD\n",
        "\n",
        "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'],\n",
        "                                   as_index=False).agg({'account':'count'})\n",
        "\n",
        "# Sort pop_vac_lic and print the results\n",
        "sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant', 'account', 'pop_2010'],\n",
        "                                             ascending=[False, True, True])\n",
        "print(sorted_pop_vac_lic.head())\n",
        "print()\n",
        "\n",
        "# THE GOAL HERE ABOVE WAS TO FIND A PLACE WITH FEW POPULATION,\n",
        "# MANY VACANT PLACES AND FEW BUSINESSES (BY THE ACCOUNT N#)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKfO60XGho5h",
        "outputId": "56d7a78f-c910-44ba-c059-4302679574c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ward  residential  commercial  industrial  vacant  other\n",
            "0    1           41           9           2       2     46\n",
            "1    2           31          11           6       2     50\n",
            "2    3           20           5           3      13     59\n",
            "3    4           22          13           0       7     58\n",
            "4    5           25           3           1       3     68\n",
            "\n",
            "  ward  pop_2000  pop_2010 change                                  address  \\\n",
            "0    1     52951     56149     6%              2765 WEST SAINT MARY STREET   \n",
            "1    2     54361     55805     3%                 WM WASTE MANAGEMENT 1500   \n",
            "2    3     40385     53039    31%                      17 EAST 38TH STREET   \n",
            "3    4     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL   \n",
            "4    5     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE   \n",
            "\n",
            "     zip  \n",
            "0  60647  \n",
            "1  60622  \n",
            "2  60653  \n",
            "3  60653  \n",
            "4  60637  \n",
            "\n",
            "  account ward  aid                   business               address    zip\n",
            "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
            "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
            "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
            "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
            "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613\n",
            "\n",
            "Index(['ward', 'residential', 'commercial', 'industrial', 'vacant', 'other',\n",
            "       'pop_2000', 'pop_2010', 'change', 'address_cen', 'zip_cen', 'account',\n",
            "       'aid', 'business', 'address_lic', 'zip_lic'],\n",
            "      dtype='object')\n",
            "\n",
            "   ward  pop_2010  vacant  account\n",
            "47    7     51581      19       80\n",
            "12   20     52372      15      123\n",
            "1    10     51535      14      130\n",
            "16   24     54909      13       98\n",
            "7    16     51954      13      156\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LEFT JOIN"
      ],
      "metadata": {
        "id": "RXVD_9c-X3Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting missing rows with left join\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# READING FILES\n",
        "\n",
        "\n",
        "path16 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/movies.p'\n",
        "\n",
        "movies = pd.read_pickle(path16)\n",
        "\n",
        "path17 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/financials.p'\n",
        "\n",
        "financials = pd.read_pickle(path17)\n",
        "\n",
        "print(movies.head())\n",
        "print(movies.shape)\n",
        "print(financials.head())\n",
        "print(financials.shape)\n",
        "\n",
        "# Merge movies and financials with a left join\n",
        "movies_financials = movies.merge(financials, on = 'id', how = 'left')\n",
        "\n",
        "# TO DISCOVER HOW MANY LINES ARE MISSING FROM THE SECOND DATAFRAME, JUST CALCULATE\n",
        "# THE NUMBER OF LINES THAT CONTAINS \"NAN\" VALUES\n",
        "\n",
        "\n",
        "# Merge the movies table with the financials table with a left join\n",
        "movies_financials = movies.merge(financials, on='id', how='left')\n",
        "\n",
        "# Count the number of rows in the budget column that are missing\n",
        "number_of_missing_fin = movies_financials['budget'].isna().sum()\n",
        "\n",
        "# Print the number of movies missing financials\n",
        "print(number_of_missing_fin)\n",
        "\n",
        "# When performing a left join, the .merge() method returns a row full of null values for columns in the right table if the key column does not have a matching value in both tables."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxY-9vdlYMZb",
        "outputId": "0170a358-d4b4-40ee-acaf-01481ab5ca57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id                 title  popularity release_date\n",
            "0    257          Oliver Twist   20.415572   2005-09-23\n",
            "1  14290  Better Luck Tomorrow    3.877036   2002-01-12\n",
            "2  38365             Grown Ups   38.864027   2010-06-24\n",
            "3   9672              Infamous    3.680896   2006-11-16\n",
            "4  12819       Alpha and Omega   12.300789   2010-09-17\n",
            "(4803, 4)\n",
            "       id     budget       revenue\n",
            "0   19995  237000000  2.787965e+09\n",
            "1     285  300000000  9.610000e+08\n",
            "2  206647  245000000  8.806746e+08\n",
            "3   49026  250000000  1.084939e+09\n",
            "4   49529  260000000  2.841391e+08\n",
            "(3229, 3)\n",
            "1574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enriching a dataset\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# READING FILES\n",
        "\n",
        "\n",
        "path18 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/toy_story.p'\n",
        "\n",
        "toy_story = pd.read_pickle(path18)\n",
        "\n",
        "path19 = '/content/drive/MyDrive/Colab Notebooks/Join Data with Pandas/Datasets/taglines.p'\n",
        "\n",
        "taglines = pd.read_pickle(path19)\n",
        "\n",
        "print(toy_story)\n",
        "print()\n",
        "print(taglines)\n",
        "print()\n",
        "\n",
        "# Merge the toy_story and taglines tables with a left join\n",
        "toystory_tag = toy_story.merge(taglines, on = 'id', how = 'left')\n",
        "\n",
        "# Print the rows and shape of toystory_tag\n",
        "print(toystory_tag)\n",
        "print(toystory_tag.shape)\n",
        "\n",
        "# AFTER MERGING, IT WAS POSSIBLE TO NOTICE THAT THERE IS NO TAGLINE INFORMATION ABOUT TOY STORY\n",
        "\n",
        "\n",
        "# Merge the toy_story and taglines tables with a inner join\n",
        "toystory_tag = toy_story.merge(taglines, on = 'id')\n",
        "\n",
        "# Print the rows and shape of toystory_tag\n",
        "print(toystory_tag)\n",
        "print(toystory_tag.shape)\n",
        "\n",
        "# A LEFT join will return all of the rows of your left table, while using an INNER join may result in lost data if it does not exist in both tables.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzGkQAO_uAk-",
        "outputId": "22432114-cb05-4b8a-8f7b-220956ee0e8b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id        title  popularity release_date\n",
            "0  10193  Toy Story 3      59.995   2010-06-16\n",
            "1    863  Toy Story 2      73.575   1999-10-30\n",
            "2    862    Toy Story      73.640   1995-10-30\n",
            "\n",
            "          id                                            tagline\n",
            "0      19995                        Enter the World of Pandora.\n",
            "1        285     At the end of the world, the adventure begins.\n",
            "2     206647                              A Plan No One Escapes\n",
            "3      49026                                    The Legend Ends\n",
            "4      49529               Lost in our world, found in another.\n",
            "...      ...                                                ...\n",
            "4795  124606            Sometimes you've got to break the rules\n",
            "4796   14337                 What happens if it actually works?\n",
            "4798    9367  He didn't come looking for trouble, but troubl...\n",
            "4799   72766  A newlywed couple's honeymoon is upended by th...\n",
            "4801  126186                           A New Yorker in Shanghai\n",
            "\n",
            "[3955 rows x 2 columns]\n",
            "\n",
            "      id        title  popularity release_date                   tagline\n",
            "0  10193  Toy Story 3      59.995   2010-06-16  No toy gets left behind.\n",
            "1    863  Toy Story 2      73.575   1999-10-30        The toys are back!\n",
            "2    862    Toy Story      73.640   1995-10-30                       NaN\n",
            "(3, 5)\n",
            "      id        title  popularity release_date                   tagline\n",
            "0  10193  Toy Story 3      59.995   2010-06-16  No toy gets left behind.\n",
            "1    863  Toy Story 2      73.575   1999-10-30        The toys are back!\n",
            "(2, 5)\n"
          ]
        }
      ]
    }
  ]
}